# Feature Selection Graph Code

feature_names = ["age", "sex", "cp", "trestbps", "chol", "fbs", "restecg",
                 "thalach", "exang", "oldpeak", "slope", "ca", "thal", "target"]
plt.bar(feature_names, feature_selection.scores_)
plt.xlabel("Features")
plt.ylabel("Score")
plt.title("Feature Selection Scores")
plt.show()

# SMOTE Scatterplot Code
# print(unprocessed_data_X)
g1 = unprocessed_data_X.loc[:, "age":"target"]
plt.scatter('trestbps', 'chol', data=g1)

# Scatterplot for SMOTE treated data
# Convert SMOTE-treated data numpy array to DataFrame to use .loc
smoteDF = pd.DataFrame(smote_processed_data_X)
smoteDF.to_csv("SMOTEData.csv")

# print(smoteDF)
g2 = smoteDF.loc[1025:1051, :]  # New data from SMOTE
# print (g2)
smoteDF.plot(x=3, y=4, kind='scatter')

# RF Confusion Matrix Graph Code

cm = confusion_matrix(smote_test_Y, random_forest_smote_predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title("SMOTE-treated RF Confusion Matrix")
plt.show()

cm = confusion_matrix(processed_test_Y, random_forest_processed_predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title("Preprocessed RF Confusion Matrix")
plt.show()

# Learning Curve Graph Code

train_sizes_abs, train_scores, test_scores = learning_curve(
    random_forest_smote,
    smote_processed_data_X,
    smote_processed_data_Y,
    train_sizes=np.linspace(0.1, 1.0, 10)
)

test_scores_mean = np.mean(test_scores, axis=1)

plt.plot(train_sizes_abs, test_scores_mean,
         label="SMOTE-treated RF Learning Curve")

train_sizes_abs, train_scores, test_scores = learning_curve(
    random_forest_processed,
    processed_data_X,
    processed_data_Y,
    train_sizes=np.linspace(0.1, 1.0, 10)
)
test_scores_mean = np.mean(test_scores, axis=1)

plt.plot(train_sizes_abs, test_scores_mean,
         label="Preprocessed RF Learning Curve")

plt.title("RF Learning Curves")
plt.xlabel("Training Subset Size")
plt.ylabel("Accuracy")

plt.legend()
plt.show()

# Performance of the Models Bar Graph Code

model_labels = ['RF w/ SMOTE', 'RF w/o SMOTE']

accuracy = [random_forest_smote_accuracy, random_forest_processed_accuracy, ]

precision = [random_forest_smote_report['macro avg']['precision'],
             random_forest_processed_report['macro avg']['precision']]
recall = [random_forest_smote_report['macro avg']['recall'],
          random_forest_processed_report['macro avg']['recall'], ]
f1_score = [random_forest_smote_report['macro avg']['f1-score'],
            random_forest_processed_report['macro avg']['f1-score']]
x = np.arange(len(model_labels))
print(x)
width = 0.1
fig, ax = plt.subplots()
rects1 = ax.bar(x - width - width/2, accuracy, width, label='Accuracy')
rects2 = ax.bar(x - width/2, precision, width, label='Precision')
rects3 = ax.bar(x + width/2, recall, width, label='Recall')
rects4 = ax.bar(x + width + width/2, f1_score, width, label='F1-Score')

ax.set_title('Performance of the Models')
ax.set_xticks(x, model_labels)
ax.legend()

ax.bar_label(rects1, padding=3, fmt='%.2f')
ax.bar_label(rects2, padding=3, fmt='%.2f')
ax.bar_label(rects3, padding=3, fmt='%.2f')
ax.bar_label(rects4, padding=3, fmt='%.2f')

fig.tight_layout()

plt.ylim(0.75, 0.90)
plt.show()